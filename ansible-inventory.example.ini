# this is an example ansible-inventory for NIployments, 
# there are three sections: routers, controlplane and workers. 
# (nodes is a parent group of controlplane and workers)

[routers]
#while unusual, you can define multiple routers.
#You MUST always have only 1 router that is master, for VRRP.
# while bootstrapping you MUST leave this group out, but you will be asked to fill it in.

#router1 ansible_ssh_host=10.0.0.1 master=true
#router2 ansible_ssh_host=10.0.0.2 master=false

[controlplane]
# These are the kind of nodes that are responsible for managing
# the Kubernetes cluster, to make a cluster High Availability,
# you should have at least 3 controlplane nodes.

# if you wish, you can specify an alias for a node, or you can just specify
# the ip address as shown below:

# you need to always define the ansible_ssh_host and ansible_ssh_private_key_file because they will be changed automatically
# you maybe to need to define the external interface (that will be given to the router, alongside the whole PCI device). 


#node1 ansible_ssh_host=10.0.0.2 ansible_ssh_private_key_file=/path/to/private_key
#node1 ansible_ssh_host=10.0.0.2 ansible_ssh_private_key_file=/path/to/private_key external_interface=enp1f0


#any node can be used to setup zfs pools
#node2 ansible_ssh_host=192.168.121.184 ansible_user=ni ansible_ssh_private_key_file=node/bootstrap_key storage=true


[workers]
# These kinds of nodes are also connected to Kubernetes cluster,
# but don't have any management services on them. 

#10.0.0.5
#10.0.0.6

[nodes:children]
controlplane
workers

[all:vars]
dev_cluster=false
ansible_python_interpreter="/usr/bin/env python3"